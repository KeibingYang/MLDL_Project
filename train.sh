#!/bin/bash

echo "ğŸš€ Starting Florence-2 DocVQA Multi-Stage Fine-tuning..."
echo "================================================================"

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# æ£€æŸ¥Pythonç¯å¢ƒ
echo "ğŸ“‹ Checking Python environment..."
python --version
echo "ğŸ“‹ Checking CUDA availability..."
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# æ£€æŸ¥å¿…è¦çš„ä¾èµ–
echo "ğŸ“‹ Checking required packages..."
python -c "
import torch
import transformers
import datasets
from PIL import Image
import matplotlib.pyplot as plt
from rapidfuzz.distance import Levenshtein
import numpy as np
print('âœ… All required packages are available')
"

# åˆ›å»ºè¾“å‡ºç›®å½•
echo "ğŸ“‚ Creating output directories..."
mkdir -p logs
mkdir -p results
mkdir -p visualizations

# å¯åŠ¨è®­ç»ƒ
echo "ğŸ‹ï¸ Starting training pipeline..."
python finetune.py 2>&1 | tee logs/training_$(date +%Y%m%d_%H%M%S).log

# æ£€æŸ¥è®­ç»ƒç»“æœ
if [ $? -eq 0 ]; then
    echo "âœ… Training completed successfully!"
    echo "ğŸ“Š Results saved in:"
    echo "   - Logs: logs/"
    echo "   - Visualizations: visualization_*/"
    echo "   - Final results: final_results_all_stages.json"
else
    echo "âŒ Training failed! Check the logs for details."
    exit 1
fi

echo "================================================================"
echo "ğŸ‰ Florence-2 DocVQA training pipeline completed!"
